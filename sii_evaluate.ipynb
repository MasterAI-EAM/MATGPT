{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8133064",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_1_schema = [\n",
    "'Substrate_stack_sequence',\n",
    "'ETL_stack_sequence',\n",
    "'ETL_additives_compounds',\n",
    "'ETL_deposition_procedure',\n",
    "'Perovskite_composition_long_form',\n",
    "'Perovskite_composition_short_form',\n",
    "'Perovskite_additives_compounds',\n",
    "'Perovskite_deposition_solvents',\n",
    "'Perovskite_deposition_procedure',\n",
    "'Perovskite_deposition_thermal_annealing_temperature',\n",
    "'Perovskite_deposition_thermal_annealing_time',\n",
    "'HTL_stack_sequence',\n",
    "'HTL_additives_compounds',\n",
    "'HTL_deposition_procedure',\n",
    "'Backcontact_stack_sequence',\n",
    "'Backcontact_additives_compounds',\n",
    "'Backcontact_deposition_procedure',\n",
    "'Stability_measured',\n",
    "'Stability_average_over_n_number_of_cells',\n",
    "'Stability_temperature_range',\n",
    "'Stability_atmosphere',\n",
    "'Stability_time_total_exposure',\n",
    "'Stability_PCE_initial_value',\n",
    "'Stability_PCE_end_of_experiment',\n",
    "'Cell_area_measured',\n",
    "'Cell_number_of_cells_per_substrate',\n",
    "'Cell_architecture',\n",
    "'Cell_flexible',\n",
    "'Cell_semitransparent',\n",
    "'Cell_semitransparent_wavelength_range',\n",
    "'Module'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4c1fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_set = ['Substrate_stack_sequence', \n",
    "         'ETL_stack_sequence',\n",
    "         'ETL_additives_compounds',\n",
    "         'Perovskite_composition_long_form', \n",
    "         'Perovskite_composition_short_form', \n",
    "         'Perovskite_additives_compounds',\n",
    "         'HTL_stack_sequence',\n",
    "         'HTL_additives_compounds', \n",
    "         'Backcontact_stack_sequence',\n",
    "         'Backcontact_additives_compounds']\n",
    "b_set = ['Cell_area_measured', \n",
    "         'Cell_number_of_cells_per_substrate', \n",
    "         'Cell_architecture', \n",
    "         'Cell_flexible', \n",
    "         'Cell_semitransparent', \n",
    "         'Cell_semitransparent_wavelength_range']\n",
    "c_set = ['ETL_deposition_procedure', \n",
    "         'HTL_deposition_procedure',\n",
    "         'Backcontact_deposition_procedure',\n",
    "         'Perovskite_deposition_procedure',\n",
    "         'Perovskite_deposition_solvents', \n",
    "         'Perovskite_deposition_thermal_annealing_temperature', \n",
    "         'Perovskite_deposition_thermal_annealing_time']\n",
    "d_set = ['Stability_measured', \n",
    "         'Stability_average_over_n_number_of_cells', \n",
    "         'Stability_temperature_range', \n",
    "         'Stability_atmosphere', \n",
    "         'Stability_time_total_exposure', \n",
    "         'Stability_PCE_initial_value', \n",
    "         'Stability_PCE_end_of_experiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd900f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_float(num_str):\n",
    "    try:\n",
    "        float(num_str)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a27c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_match(single_answer, single_prediction):\n",
    "    a_words = single_answer[1].replace('|',';').replace(':',';').replace('>>',';').replace('Spin-coating','spin-coated').split(';')\n",
    "    p_words = single_prediction[1].replace('|',';').replace(':',';').replace('>>',';').replace('Spin-coating','spin-coated').split(';')\n",
    "    a_words = [x.strip() for x in a_words]\n",
    "    p_words = [x.strip() for x in p_words]\n",
    "    # 在prediction里但不在answer里，则为fp\n",
    "    # 在answer里但不在prediction里，则为fn\n",
    "    # 都在则为tp\n",
    "    tp = []\n",
    "    fp = []\n",
    "    fn = []\n",
    "    if single_answer[0] in ['ETL_stack_sequence', 'HTL_stack_sequence', 'Substrate_stack_sequence']:\n",
    "        answerSet = set()\n",
    "        outputSet = set()\n",
    "        for answer in a_words:\n",
    "            for ap in answer.split(\"-\"):\n",
    "                answerSet.add(ap)\n",
    "        for output in p_words:\n",
    "            for op in output.split(\"-\"):\n",
    "                outputSet.add(op)\n",
    "        a_words = list(answerSet)\n",
    "        p_words = list(outputSet)\n",
    "    elif 'procedure' in single_answer[0] or single_answer[0] == 'Stability_atmosphere':\n",
    "        answerSet = set()\n",
    "        outputSet = set()\n",
    "        for answer in a_words:\n",
    "            answerSet.add(answer.lower())\n",
    "        for output in p_words:\n",
    "            outputSet.add(output.lower())\n",
    "        a_words = list(answerSet)\n",
    "        p_words = list(outputSet)\n",
    "    elif 'temperature' in single_answer[0] or 'time' in single_answer[0]:\n",
    "        answerSet = set()\n",
    "        outputSet = set()\n",
    "        for answer in a_words:\n",
    "            if answer != 'nan' and answer != '' and answer != 'Unknown':\n",
    "                answerSet.add(str(float(answer)))\n",
    "            else:\n",
    "                answerSet.add(answer)\n",
    "        for output in p_words:\n",
    "            if output != 'nan' and output!='' and output != 'Unknown':\n",
    "                outputSet.add(str(float(output)))\n",
    "            else:\n",
    "                outputSet.add(output)\n",
    "        a_words = list(answerSet)\n",
    "        p_words = list(outputSet)\n",
    "    tmp_predictions = p_words\n",
    "    if single_answer[0] in ['Perovskite_composition_long_form', 'Perovskite_composition_short_form']:\n",
    "        tmp = []\n",
    "        for p in p_words:\n",
    "            for aw in a_words:\n",
    "                if p == aw:\n",
    "                    tp.append(p)\n",
    "                else:\n",
    "                    answer_word_set = set(aw.strip())\n",
    "                    output_word_set = set(p.strip())\n",
    "                    if answer_word_set.issubset(output_word_set) or output_word_set.issubset(answer_word_set):\n",
    "                        tp.append(p)\n",
    "                        tmp.append(aw)\n",
    "                        tmp_predictions.remove(p)\n",
    "                        tmp_predictions.append(aw)\n",
    "        for p in p_words:\n",
    "            if p not in tp:\n",
    "                fp.append(p)\n",
    "        for aw in a_words:\n",
    "            if aw not in tmp and aw not in tp:\n",
    "                fn.append(aw)\n",
    "    else:\n",
    "        for p in p_words:\n",
    "            if p.strip() in a_words:\n",
    "                tp.append(p.strip())\n",
    "            else:\n",
    "                fp.append(p.strip())\n",
    "        for aw in a_words:\n",
    "            if aw.strip() not in p_words:\n",
    "                fn.append(aw.strip())\n",
    "    return [tp, fp, fn, a_words, tmp_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db39772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(tp, fp, fn, ac):\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = precision*recall*2/(precision+recall)\n",
    "    acc = tp/ac\n",
    "    return round(precision,4), round(recall,4), round(f1,4), round(acc,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a694dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation(a1, a2, p1, p2):\n",
    "    aas = []\n",
    "    pps = []\n",
    "    for a1_ in a1:\n",
    "        for a2_ in a2:\n",
    "            aas.append((a1_, a2_))\n",
    "    for p1_ in p1:\n",
    "        for p2_ in p2:\n",
    "            pps.append((p1_, p2_))\n",
    "    tp = []\n",
    "    fp = []\n",
    "    fn = []\n",
    "    for pps_ in pps:\n",
    "        if pps_ in aas:\n",
    "            tp.append(pps_)\n",
    "        else:\n",
    "            fp.append(pps_)\n",
    "    for aas_ in aas:\n",
    "        if aas_ not in pps:\n",
    "            fn.append(aas_)\n",
    "    return [tp, fp, fn, aas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2498287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation_2(a1, a2, a3, a4, p1, p2, p3, p4):\n",
    "    aas = []\n",
    "    pps = []\n",
    "    for a1_ in a1:\n",
    "        for a2_ in a2:\n",
    "            for a3_ in a3:\n",
    "                for a4_ in a4:\n",
    "                    aas.append((a1_, a2_, a3_, a4_))\n",
    "    for p1_ in p1:\n",
    "        for p2_ in p2:\n",
    "            for p3_ in p3:\n",
    "                for p4_ in p4:\n",
    "                    pps.append((p1_, p2_, p3_, p4_))\n",
    "    tp = []\n",
    "    fp = []\n",
    "    fn = []\n",
    "    for pps_ in pps:\n",
    "        if pps_ in aas:\n",
    "            tp.append(pps_)\n",
    "        else:\n",
    "            fp.append(pps_)\n",
    "    for aas_ in aas:\n",
    "        if aas_ not in pps:\n",
    "            fn.append(aas_)\n",
    "    return [tp, fp, fn, aas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ccca89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(answers, predictions):\n",
    "    keys = ['tp', 'fp', 'fn', 'ans', 'pre']\n",
    "    store = {'tp':{'total':0},'fp':{'total':0},'fn':{'total':0},'ans':{'total':0}, 'pre':{'total':0}}\n",
    "    metrics_dict = {}\n",
    "    for i, answer in enumerate(list(answers.items())):       \n",
    "        if answer[0] in predictions.keys():\n",
    "            acc_prediction = (answer[0], predictions[answer[0]])\n",
    "        else:\n",
    "            return None\n",
    "        # print(answer, acc_prediction[1])\n",
    "        metrics = single_match(answer, acc_prediction)\n",
    "        for idx in range(4):\n",
    "            store[keys[idx]]['total'] +=len(metrics[idx])\n",
    "        if answer[0] in a_set or answer[0] in b_set or answer[0] in c_set or answer[0] in d_set:\n",
    "        # if answer[0] in b_set:\n",
    "            for idx in range(5):\n",
    "                store[keys[idx]][answer[0]]=metrics[idx]\n",
    "    # information extraction      \n",
    "    metrics_dict['ie'] = calculate_metrics(store['tp']['total'], store['fp']['total'], store['fn']['total'], store['ans']['total'])\n",
    "    # relationship extraction: ab, ac, abc-d\n",
    "    ab_metrics = [0,0,0,0]\n",
    "    for a in a_set:\n",
    "        for b in b_set:\n",
    "            relations = relation(store['ans'][a], store['ans'][b], store['pre'][a], store['pre'][b])\n",
    "            for i in range(4):\n",
    "                ab_metrics[i] += len(relations[i])\n",
    "    metrics_dict['ab'] = calculate_metrics(ab_metrics[0], ab_metrics[1], ab_metrics[2], ab_metrics[3])\n",
    "    ac_metrics = [0,0,0,0]\n",
    "    for a in a_set:\n",
    "        for c in c_set:\n",
    "            if a.split('_')[0] == c.split('_')[0]:\n",
    "                relations = relation(store['ans'][a], store['ans'][c], store['pre'][a], store['pre'][c])\n",
    "                # print(relations)\n",
    "                for i in range(4):\n",
    "                    ac_metrics[i] += len(relations[i])\n",
    "    metrics_dict['ac'] = calculate_metrics(ac_metrics[0], ac_metrics[1], ac_metrics[2], ac_metrics[3])\n",
    "    abc_d_metrics = [0,0,0,0]\n",
    "    for a in a_set:\n",
    "        for b in b_set:\n",
    "            for c in c_set:\n",
    "                for d in d_set:\n",
    "                    if a.split('_')[0] == c.split('_')[0]:\n",
    "                        relations = relation_2(store['ans'][a], store['ans'][b], store['ans'][c], store['ans'][d], store['pre'][a], store['pre'][b], store['pre'][c], store['pre'][d])\n",
    "                # print(relations)\n",
    "                for i in range(4):\n",
    "                    abc_d_metrics[i] += len(relations[i])\n",
    "    metrics_dict['abc_d'] = calculate_metrics(abc_d_metrics[0], abc_d_metrics[1], abc_d_metrics[2], abc_d_metrics[3])\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f155d09",
   "metadata": {},
   "source": [
    "# load output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "247096af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "p = []\n",
    "a = []\n",
    "p_text = []\n",
    "a_text = []\n",
    "len_schema = stage_1_schema.copy()\n",
    "len_schema.sort(key = lambda y:len(y),reverse=True)  \n",
    "# print(len_schema)\n",
    "with open('../sii40_output.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.readlines()\n",
    "    for i ,d in enumerate(data):\n",
    "        if d.startswith('prediction'):\n",
    "            p.append(i)\n",
    "        if d.startswith('answer'):\n",
    "            a.append(i)\n",
    "    for i, ip in enumerate(p):\n",
    "        tmp = ''\n",
    "        for d in data[ip:a[i]+1]:\n",
    "            tmp+=d\n",
    "        tmp = tmp.replace('Fig. 1. ', '')\n",
    "        tmp = tmp.replace('<s>', '')\n",
    "        tmp = tmp.replace('</s>', '')\n",
    "        tmp_schema = {}\n",
    "        for ls in len_schema:\n",
    "            for t in tmp.split('\\n'):\n",
    "                if ls in t:\n",
    "                    pos = t.find(ls+': ')\n",
    "                    value = t[pos+len(ls+': '):]\n",
    "                    if ls not in tmp_schema.keys():   \n",
    "                        if value.endswith(','):\n",
    "                            value = value[:-1]\n",
    "                        if '#' in value:\n",
    "                            value = value.replace('#', '')\n",
    "                        tmp_schema[ls] = value.strip()\n",
    "        p_text.append(tmp_schema)\n",
    "        # print(tmp_schema)\n",
    "        # print('\\n')\n",
    "    for i, ia in enumerate(a):\n",
    "        tmp = ''\n",
    "        if i!=39:\n",
    "            end = p[i+1]\n",
    "        else:\n",
    "            end = len(data)\n",
    "        for d in data[ia:end]:\n",
    "            tmp+=d\n",
    "        \n",
    "        tmp = tmp.replace('answer --> ', '')\n",
    "        tmp = tmp.replace('<s>', '')\n",
    "        tmp = tmp.replace('</s>', '')\n",
    "        tmp_schema = {}\n",
    "        for idx, t in enumerate(tmp.split('\\n')[:-1]):\n",
    "            sche = stage_1_schema[idx]\n",
    "            if sche in t:\n",
    "                value = t.replace(sche+': ', '')\n",
    "                if sche == 'Module':\n",
    "                    tmp_schema[sche] = value.strip()\n",
    "                else:\n",
    "                    tmp_schema[sche] = value[:-1].strip()\n",
    "        a_text.append(tmp_schema)\n",
    "        # print(tmp_schema)\n",
    "        # print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae636a1",
   "metadata": {},
   "source": [
    "# IE + RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d132cafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ie_total (0.8834, 0.8611, 0.8714, 0.8611)\n",
      "ab_relation (0.7886, 0.7531, 0.7681, 0.7531)\n",
      "ac_relation (0.7263, 0.6722, 0.6942, 0.6722)\n",
      "abc_d_relation (0.7197, 0.6584, 0.6823, 0.6584)\n"
     ]
    }
   ],
   "source": [
    "# round(precision,4), round(recall,4), round(f1,4), round(acc,4)\n",
    "def total(metric):\n",
    "    p = 0\n",
    "    r = 0\n",
    "    f = 0\n",
    "    a = 0\n",
    "    for i in metric:\n",
    "        p += i[0]\n",
    "        r += i[1]\n",
    "        f += i[2]\n",
    "        a += i[3]\n",
    "    precision = p/len(metric)\n",
    "    recall = r/len(metric)\n",
    "    f1 = f/len(metric)\n",
    "    acc = a/len(metric)\n",
    "    return round(precision,4), round(recall,4), round(f1,4), round(acc,4)\n",
    "\n",
    "ie = []\n",
    "ab = []\n",
    "ac = []\n",
    "abc_d = []\n",
    "for i, p in enumerate(p_text):\n",
    "    # print(p)\n",
    "    # print(a_text[i])\n",
    "    m = metrics(a_text[i], p)\n",
    "    if m:\n",
    "        ie.append(m['ie'])\n",
    "        ab.append(m['ab'])\n",
    "        ac.append(m['ac'])\n",
    "        abc_d.append(m['abc_d'])\n",
    "print('ie_total', total(ie))\n",
    "print('ab_relation', total(ab))\n",
    "print('ac_relation', total(ac))\n",
    "print('abc_d_relation', total(abc_d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251270b5",
   "metadata": {},
   "source": [
    "# each set IE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f51c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_single(answers, predictions, set_name):\n",
    "    keys = ['tp', 'fp', 'fn', 'ans', 'pre']\n",
    "    store = {'tp':{'total':0},'fp':{'total':0},'fn':{'total':0},'ans':{'total':0}, 'pre':{'total':0}}\n",
    "    metrics_dict = {}\n",
    "    for i, answer in enumerate(list(answers.items())): \n",
    "        if answer[0] in set_name:\n",
    "            if answer[0] in predictions.keys():\n",
    "                acc_prediction = (answer[0], predictions[answer[0]])\n",
    "            else:\n",
    "                return None\n",
    "            metrics = single_match(answer, acc_prediction)\n",
    "            for idx in range(4):\n",
    "                store[keys[idx]]['total'] +=len(metrics[idx])\n",
    "            for idx in range(5):\n",
    "                store[keys[idx]][answer[0]]=metrics[idx]     \n",
    "    metrics_dict['ie'] = calculate_metrics(store['tp']['total'], store['fp']['total'], store['fn']['total'], store['ans']['total'])\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "432300d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_ie (0.8354, 0.8123, 0.821, 0.8123)\n",
      "b_ie (0.902, 0.902, 0.902, 0.902)\n",
      "c_ie (0.828, 0.7831, 0.8014, 0.7831)\n",
      "d_ie (0.9796, 0.9796, 0.9796, 0.9796)\n"
     ]
    }
   ],
   "source": [
    "# round(precision,4), round(recall,4), round(f1,4), round(acc,4)\n",
    "a = []\n",
    "b = []\n",
    "c = []\n",
    "d = []\n",
    "for i, p in enumerate(p_text):\n",
    "    m = metrics_single(a_text[i], p, a_set)\n",
    "    if m:\n",
    "        a.append(m['ie'])\n",
    "for i, p in enumerate(p_text):\n",
    "    m = metrics_single(a_text[i], p, b_set)\n",
    "    if m:\n",
    "        b.append(m['ie'])\n",
    "for i, p in enumerate(p_text):\n",
    "    m = metrics_single(a_text[i], p, c_set)\n",
    "    if m:\n",
    "        c.append(m['ie'])\n",
    "for i, p in enumerate(p_text):\n",
    "    m = metrics_single(a_text[i], p, d_set)\n",
    "    if m:\n",
    "        d.append(m['ie'])\n",
    "\n",
    "print('a_ie', total(a))\n",
    "print('b_ie', total(b))\n",
    "print('c_ie', total(c))\n",
    "print('d_ie', total(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b76a4",
   "metadata": {},
   "source": [
    "# deduction, normalization, summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3afa7a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "deduction = ['Cell_area_measured', 'Cell_architecture', 'Cell_semitransparent']\n",
    "normalization = ['Perovskite_deposition_thermal_annealing_time', 'Stability_time_total_exposure', 'Cell_area_measured']\n",
    "summarization=['Substrate_stack_sequence', 'ETL_stack_sequence', 'Perovskite_composition_short_form', 'HTL_stack_sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "825717d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('original_text.json', 'r', encoding='utf-8') as f:\n",
    "    prompts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e8740f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "{'Perovskite_deposition_thermal_annealing_temperature': '90', 'Perovskite_deposition_thermal_annealing_time': '40', 'Stability_average_over_n_number_of_cells': '1', 'Cell_semitransparent_wavelength_range': 'nan; nan', 'Cell_number_of_cells_per_substrate': '0', 'Perovskite_composition_short_form': 'MAPbI', 'Perovskite_composition_long_form': 'MAPbI3', 'Backcontact_deposition_procedure': 'Evaporation', 'Perovskite_deposition_procedure': 'Spin-coating', 'Backcontact_additives_compounds': '', 'Stability_PCE_end_of_experiment': '', 'Perovskite_additives_compounds': '', 'Perovskite_deposition_solvents': 'Unknown', 'Stability_time_total_exposure': '', 'Stability_temperature_range': 'nan; nan', 'Stability_PCE_initial_value': '', 'Backcontact_stack_sequence': 'Ag', 'Substrate_stack_sequence': 'SLG | ITO', 'ETL_deposition_procedure': 'Spin-coating', 'HTL_deposition_procedure': 'Spin-coating', 'ETL_additives_compounds': 'BCP', 'HTL_additives_compounds': '', 'Stability_atmosphere': 'Unknown', 'Cell_semitransparent': 'FALSE', 'ETL_stack_sequence': 'PCBM-60', 'HTL_stack_sequence': 'PEDOT:PSS', 'Stability_measured': 'FALSE', 'Cell_area_measured': '0.1', 'Cell_architecture': 'pin', 'Cell_flexible': 'FALSE', 'Module': 'FALSE'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "p = []\n",
    "a = []\n",
    "p_text = []\n",
    "a_text = []\n",
    "len_schema = stage_1_schema.copy()\n",
    "len_schema.sort(key = lambda y:len(y),reverse=True)  \n",
    "# print(len_schema)\n",
    "with open('../sii40_output.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.readlines()\n",
    "    for i ,d in enumerate(data):\n",
    "        if d.startswith('prediction'):\n",
    "            p.append(i)\n",
    "        if d.startswith('answer'):\n",
    "            a.append(i)\n",
    "    for i, ip in enumerate(p):\n",
    "        tmp = ''\n",
    "        for d in data[ip:a[i]+1]:\n",
    "            tmp+=d\n",
    "        tmp = tmp.replace('Fig. 1. ', '')\n",
    "        tmp = tmp.replace('<s>', '')\n",
    "        tmp = tmp.replace('</s>', '')\n",
    "        tmp_schema = {}\n",
    "        for ls in len_schema:\n",
    "            for t in tmp.split('\\n'):\n",
    "                if ls in t:\n",
    "                    pos = t.find(ls+': ')\n",
    "                    value = t[pos+len(ls+': '):]\n",
    "                    if ls not in tmp_schema.keys():   \n",
    "                        if value.endswith(','):\n",
    "                            value = value[:-1]\n",
    "                        if '#' in value:\n",
    "                            value = value.replace('#', '')\n",
    "                        tmp_schema[ls] = value.strip()\n",
    "        p_text.append(tmp_schema)\n",
    "        # print(tmp_schema)\n",
    "        # print('\\n')\n",
    "    for i, ia in enumerate(a):\n",
    "        tmp = ''\n",
    "        if i!=39:\n",
    "            end = p[i+1]\n",
    "        else:\n",
    "            end = len(data)\n",
    "        for d in data[ia:end]:\n",
    "            tmp+=d\n",
    "        \n",
    "        tmp = tmp.replace('answer --> ', '')\n",
    "        tmp = tmp.replace('<s>', '')\n",
    "        tmp = tmp.replace('</s>', '')\n",
    "        tmp_schema = {}\n",
    "        for idx, t in enumerate(tmp.split('\\n')[:-1]):\n",
    "            sche = stage_1_schema[idx]\n",
    "            if sche in t:\n",
    "                value = t.replace(sche+': ', '')\n",
    "                if sche == 'Module':\n",
    "                    tmp_schema[sche] = value.strip()\n",
    "                else:\n",
    "                    tmp_schema[sche] = value[:-1].strip()\n",
    "        a_text.append(tmp_schema)\n",
    "        # print(tmp_schema)\n",
    "        # print('\\n')\n",
    "print(len(p_text))\n",
    "print(p_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2af9bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_f_t = 0\n",
    "d_f = 0\n",
    "d_n_t = 0\n",
    "d_n = 0\n",
    "d_s_t = 0\n",
    "d_s = 0\n",
    "for i, p in enumerate(p_text):\n",
    "    for idx, a in enumerate(a_text[i].keys()):\n",
    "        if a in deduction:\n",
    "            if a in p.keys() and a_text[i][a] not in prompts[i]:\n",
    "                d_f_t += 1\n",
    "                if p[a]==a_text[i][a]:\n",
    "                    d_f += 1\n",
    "        if a in normalization:\n",
    "            if a in p.keys() and a_text[i][a] not in prompts[i]:\n",
    "                d_n_t += 1\n",
    "                if p[a]==a_text[i][a]:\n",
    "                    d_n += 1\n",
    "                else:\n",
    "                    # print(p[a], a_text[i][a])\n",
    "                    a_words = a_text[i][a].replace('; ',' >> ').replace(' | ', ' >> ').split(' >> ')\n",
    "                    p_words = p[a].replace('; ',' >> ').replace(\"''\", '').split(' >> ')\n",
    "                    for pw in p_words:\n",
    "                        if pw in a_words:\n",
    "                            d_n += 1\n",
    "                        else:\n",
    "                            # print(a_words,p_words)\n",
    "                            for aw in a_words:\n",
    "                                if if_float(pw) and if_float(aw):\n",
    "                                    if round(float(pw),1) == round(float(aw),1):\n",
    "                                        # print('sub', pw, aw)\n",
    "                                        d_n += 1\n",
    "        if a in summarization:\n",
    "            if a in p.keys(): \n",
    "                a_words = a_text[i][a].replace('|',';').replace(':',';').replace('>>',';').replace('Spin-coating','spin-coated').split(';')\n",
    "                a_words = [x.strip() for x in a_words]\n",
    "                p_words = p[a].replace('|',';').replace(':',';').replace('>>',';').replace('Spin-coating','spin-coated').split(';')\n",
    "                p_words = [x.strip() for x in p_words] \n",
    "                for aw in a_words:\n",
    "                    if aw not in prompts[i]:\n",
    "                        d_s_t += 1\n",
    "                        if aw in p_words:\n",
    "                            d_s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bcc6a788",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 70 0.7571428571428571\n",
      "29 41 0.7073170731707317\n",
      "116 154 0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "print(d_f, d_f_t, d_f/d_f_t)\n",
    "print(d_n, d_n_t, d_n/d_n_t)\n",
    "print(d_s, d_s_t, d_s/d_s_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aacba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# GPT-3 finetune result\n",
    "fine_data = []\n",
    "with open('test_output40.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.readlines()\n",
    "    for d in data:\n",
    "        if d.startswith('output'):\n",
    "            fine_data.append(d[:-1].replace('output:  ', ''))\n",
    "p_text = []\n",
    "for fd in fine_data:\n",
    "    pos = []\n",
    "    tmp_dict = {}\n",
    "    for i in stage_1_schema:\n",
    "        pos.append(fd.find(i))\n",
    "    for i, e in enumerate(stage_1_schema):\n",
    "        if i!=len(pos)-1:\n",
    "            end = pos[i+1]-2\n",
    "        else:\n",
    "            end = -1\n",
    "        if end == -1:\n",
    "            content = fd[pos[i]+2+len(e):]\n",
    "        else:\n",
    "            content = fd[pos[i]+2+len(e):end]\n",
    "        tmp_dict[e] = content.replace(\"''\", '')\n",
    "    p_text.append(tmp_dict)\n",
    "# print(len(p_text))\n",
    "# print(p_text[0])\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
